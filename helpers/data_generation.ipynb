{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Execution file for generating Research Abstract Dataset\n",
    "See 'dataset_generator.py' for implementation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import datasets as ds\n",
    "from dataset_generator import count_and_reformat, filter_list, generate_abstracts, generate_GPT_abstract, get_models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load and preprocess dataset\n",
    "This will take some time if dataset is large. This is only necessary to do once each jupyter-session as local variables are stored until session/kernel shut down."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/nicolaisivesind/.cache/huggingface/datasets/gfissore___json/gfissore--arxiv-abstracts-2021-23556c248bdbe0fc/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "660a139ac30c439593cf2d455c8f2bc3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Counting words: 100%"
     ]
    }
   ],
   "source": [
    "# Code execution\n",
    "dataset = ds.load_dataset(\"gfissore/arxiv-abstracts-2021\")['train']\n",
    "reformatted_dataset = count_and_reformat(dataset, 'abstract')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Run code segments"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 143 elements matching the filter.\n",
      "Returned list is of length 100.\n",
      "\n",
      "Found 30589 elements matching the filter.\n",
      "Returned list is of length 200.\n",
      "\n",
      "Found 139106 elements matching the filter.\n",
      "Returned list is of length 200.\n",
      "\n",
      "Found 245943 elements matching the filter.\n",
      "Returned list is of length 200.\n",
      "\n",
      "Found 428437 elements matching the filter.\n",
      "Returned list is of length 200.\n",
      "\n",
      "Found 569658 elements matching the filter.\n",
      "Returned list is of length 200.\n",
      "\n",
      "Found 463666 elements matching the filter.\n",
      "Returned list is of length 200.\n"
     ]
    }
   ],
   "source": [
    "dataset_400_600 = filter_list(data=reformatted_dataset,\n",
    "                              word_count_min=400,\n",
    "                              word_count_max=600,\n",
    "                              quantity=100)\n",
    "dataset_300_399 = filter_list(data=reformatted_dataset,\n",
    "                              word_count_min=300,\n",
    "                              word_count_max=399,\n",
    "                              quantity=200)\n",
    "dataset_250_299 = filter_list(data=reformatted_dataset,\n",
    "                              word_count_min=250,\n",
    "                              word_count_max=299,\n",
    "                              quantity=200)\n",
    "dataset_200_249 = filter_list(data=reformatted_dataset,\n",
    "                              word_count_min=200,\n",
    "                              word_count_max=249,\n",
    "                              quantity=200)\n",
    "dataset_150_199 = filter_list(data=reformatted_dataset,\n",
    "                              word_count_min=150,\n",
    "                              word_count_max=199,\n",
    "                              quantity=200)\n",
    "dataset_100_149 = filter_list(data=reformatted_dataset,\n",
    "                              word_count_min=100,\n",
    "                              word_count_max=149,\n",
    "                              quantity=200)\n",
    "dataset_50_99 = filter_list(data=reformatted_dataset,\n",
    "                              word_count_min=50,\n",
    "                              word_count_max=99,\n",
    "                              quantity=200)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV-file already exists. Will append new rows to existing document. Cancel execution if this is not intended.\n",
      "\n",
      " Generating: 200/200Abstract generation complete.\n",
      "CSV-file already exists. Will append new rows to existing document. Cancel execution if this is not intended.\n",
      "\n",
      " Generating: 45/200"
     ]
    }
   ],
   "source": [
    "generate_abstracts(data=dataset_300_399,\n",
    "                   target_file_name='research_abstracts',\n",
    "                   target_dir_path='./../../datasets/origins/research-abstracts')\n",
    "generate_abstracts(data=dataset_250_299,\n",
    "                   target_file_name='research_abstracts',\n",
    "                   target_dir_path='./../../datasets/origins/research-abstracts')\n",
    "generate_abstracts(data=dataset_200_249,\n",
    "                   target_file_name='research_abstracts',\n",
    "                   target_dir_path='./../../datasets/origins/research-abstracts')\n",
    "generate_abstracts(data=dataset_150_199,\n",
    "                   target_file_name='research_abstracts',\n",
    "                   target_dir_path='./../../datasets/origins/research-abstracts')\n",
    "generate_abstracts(data=dataset_100_149,\n",
    "                   target_file_name='research_abstracts',\n",
    "                   target_dir_path='./../../datasets/origins/research-abstracts')\n",
    "generate_abstracts(data=dataset_50_99,\n",
    "                   target_file_name='research_abstracts',\n",
    "                   target_dir_path='./../../datasets/origins/research-abstracts')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}