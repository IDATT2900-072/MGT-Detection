{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-shot learning with Bloom LLM\n",
    "This notebook contains code for testing n-shot learning for MGT detection using the LLM Bloom."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data (WikiGPT-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration aadityaubhat--GPT-wiki-intro-10ad8b711a5f3880\n",
      "Found cached dataset csv (C:/Users/andre/.cache/huggingface/datasets/aadityaubhat___csv/aadityaubhat--GPT-wiki-intro-10ad8b711a5f3880/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "ds = load_dataset(\"aadityaubhat/GPT-wiki-intro\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'url', 'title', 'wiki_intro', 'generated_intro', 'title_len', 'wiki_intro_len', 'generated_intro_len', 'prompt', 'generated_text', 'prompt_tokens', 'generated_text_tokens'],\n",
       "        num_rows: 100000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'url', 'title', 'wiki_intro', 'generated_intro', 'title_len', 'wiki_intro_len', 'generated_intro_len', 'prompt', 'generated_text', 'prompt_tokens', 'generated_text_tokens'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.train_test_split(test_size=0.33333)\n",
    "ds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare LLM (bloomz-560m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BloomForCausalLM, AutoTokenizer\n",
    "\n",
    "model = BloomForCausalLM.from_pretrained(\"bigscience/bloomz-560m\", num_labels=2).to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloomz-560m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'do_sample': True,\n",
    "    'max_new_tokens': 1,\n",
    "    'top_k': 1000,\n",
    "    'top_p': 0.999,\n",
    "    'temperature': 0.5, \n",
    "    'repetition_penalty': 2.4,\n",
    "}\n",
    "\n",
    "def complete(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(inputs[\"input_ids\"], **model_config)    \n",
    "    return tokenizer.decode(outputs[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'William Simon U\\'Ren (January 10, 1859 – March 8, 1949) was an American lawyer and political activist. U\\'Ren promoted and helped pass a corrupt practices act, the presidential primary, and direct election of U.S. senators. As a progressive, U\\'Ren championed the initiative, referendum, and recall systems in an effort to bring about a Georgist \"Single Tax\" on the unimproved value of land, but these measures were also designed to promote democracy and weaken the power of backstage elites.  His reforms in Oregon were widely copied in other states. He supported numerous other reforms, such as the interactive model of proportional representation, which was not enacted. Early life\\nWilliam Simon U\\'Ren (accent the last syllable) was born on January 10, 1859 in Lancaster, Wisconsin, the son of immigrants from Cornwall, England. Their surname was originally spelled Uren. U\\'Ren\\'s father, William Richard U\\'Ren was a socialist who worked as a blacksmith and emigrated to America owing to difficult economic conditions.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['test'][0]['wiki_intro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "873"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "max_len_example = 1000\n",
    "\n",
    "sample = \"\"\n",
    "while len(sample) > max_len_example or len(sample) == 0:\n",
    "    sample = random.choice(ds['test'])['wiki_intro']\n",
    "len(sample)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-shot testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:32<00:00,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n-shot: 2\n",
      "n_samples: 100\n",
      "\n",
      "Acc: 0.49\n",
      "False-positive: 0.19\n",
      "False-negative: 0.32\n",
      "N/A-predictions: 0.0\n",
      "\n",
      "Acc (non-N/A): 0.49\n",
      "False-positive (non-N/A): 0.19\n",
      "False-negative (non-N/A): 0.32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import random\n",
    "\n",
    "init_prompt = \"\"\"Following is a text-classification model classifying if a text is human-written or machine-generated. The following text will be classified as either 'True' or 'False', where 'True' means human-written and 'False' is machine-generated:\n",
    "[EXAMPLES]\n",
    "\n",
    "Predict:\n",
    "\"[TEXT]\"\n",
    "\n",
    "Prediction (True/False): \"\"\"\n",
    "\n",
    "false_pos = 0\n",
    "false_neg = 0\n",
    "true_pos = 0\n",
    "true_neg = 0\n",
    "na_pred = 0\n",
    "\n",
    "n = 100     # how many tests to run\n",
    "n_shot = 2  # how many examples of each label to provide\n",
    "max_len_example = 1000 # max-length of each example (so we don't run out of VRAM) - should be cleaned in dataset instead but I'm lazy atm\n",
    "\n",
    "for i in tqdm(range(n)):\n",
    "    # Sample examples for n-shot learning\n",
    "    prompt = init_prompt\n",
    "    examples = \"Examples:\\n\" if n_shot >0 else \"\"\n",
    "    for s in range(n_shot*2):\n",
    "        is_true = s>=n_shot\n",
    "        label = 'wiki_intro' if is_true else 'generated_intro'\n",
    "        sample = \"\"\n",
    "        while len(sample) > max_len_example or len(sample) == 0:\n",
    "            sample = random.choice(ds['test'])[label]\n",
    "        examples += f\"\\nExample {s+1}\\nInput: \\\"\" + sample + \"\\\"\\nExpected output: \" + str(is_true) + \"\\n\"\n",
    "    prompt = prompt.replace(\"[EXAMPLES]\", examples)\n",
    "\n",
    "    # Sample an example for prediction\n",
    "    is_true = random.randint(0,1) == 1 #(i%2 == 0)\n",
    "    label = 'wiki_intro' if is_true else 'generated_intro'\n",
    "    sample = random.choice(ds['test'])[label]\n",
    "    prompt = prompt.replace(\"[TEXT]\", sample)\n",
    "    # print(prompt)\n",
    "    # Predict and evaluate\n",
    "    prediction = complete(prompt)\n",
    "\n",
    "    if ('true' in prediction.lower() or 'yes' in prediction.lower()):\n",
    "        if (is_true):\n",
    "            true_pos += 1\n",
    "        else:\n",
    "            false_pos += 1\n",
    "    elif ('false' in prediction.lower() or 'none' in prediction.lower() or 'no' in prediction.lower()):\n",
    "        if (is_true):\n",
    "            false_neg += 1\n",
    "        else:\n",
    "            true_neg += 1\n",
    "    else:\n",
    "        print(\"N/A prediction: \" + prediction)\n",
    "        na_pred += 1\n",
    "\n",
    "sleep(0.1)\n",
    "print(f\"\"\"\n",
    "n-shot: {n_shot}\n",
    "n_samples: {n}\n",
    "\n",
    "Acc: {(true_pos + true_neg) / n}\n",
    "False-positive: {false_pos / n}\n",
    "False-negative: {false_neg / n}\n",
    "N/A-predictions: {na_pred / n}\n",
    "\n",
    "Acc (non-N/A): {(true_pos + true_neg) / (n-na_pred)}\n",
    "False-positive (non-N/A): {false_pos / (n-na_pred)}\n",
    "False-negative (non-N/A): {false_neg / (n-na_pred)}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n-shot: 2\n",
      "n_samples: 99\n",
      "\n",
      "Acc: 0.494949494949495\n",
      "False-positive: 0.1919191919191919\n",
      "False-negative: 0.32323232323232326\n",
      "N/A-predictions: 0.0\n",
      "\n",
      "Acc (non-N/A): 0.494949494949495\n",
      "False-positive (non-N/A): 0.1919191919191919\n",
      "False-negative (non-N/A): 0.32323232323232326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = i\n",
    "print(f\"\"\"\n",
    "n-shot: {n_shot}\n",
    "n_samples: {n}\n",
    "\n",
    "Acc: {(true_pos + true_neg) / n}\n",
    "False-positive: {false_pos / n}\n",
    "False-negative: {false_neg / n}\n",
    "N/A-predictions: {na_pred / n}\n",
    "\n",
    "Acc (non-N/A): {(true_pos + true_neg) / (n-na_pred)}\n",
    "False-positive (non-N/A): {false_pos / (n-na_pred)}\n",
    "False-negative (non-N/A): {false_neg / (n-na_pred)}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
