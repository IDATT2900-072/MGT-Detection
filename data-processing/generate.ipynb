{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Execution file for generating Research Abstract Dataset\n",
    "See 'dataset_generator.py' for implementation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import datasets as ds\n",
    "from data_generator import count_and_reformat, filter_list, generate_abstracts, generate_GPT_abstract, get_models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load and preprocess dataset\n",
    "This will take some time if dataset is large. This is only necessary to do once each jupyter-session as local variables are stored until session/kernel shut down."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/nicolaisivesind/.cache/huggingface/datasets/gfissore___json/gfissore--arxiv-abstracts-2021-23556c248bdbe0fc/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2f2e97fa755c498e93871760f76541fc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Counting words: 100%"
     ]
    }
   ],
   "source": [
    "# Code execution\n",
    "dataset = ds.load_dataset(\"gfissore/arxiv-abstracts-2021\")['train']\n",
    "reformatted_dataset = count_and_reformat(dataset=dataset,\n",
    "                                  count_column='abstract',\n",
    "                                  retain_columns=['title', 'abstract'])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Run code segments"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 143 elements matching the filter.\n",
      "Returned list is of length 100.\n",
      "\n",
      "Found 30589 elements matching the filter.\n",
      "Returned list is of length 1400.\n",
      "\n",
      "Found 139106 elements matching the filter.\n",
      "Returned list is of length 1500.\n",
      "\n",
      "Found 245943 elements matching the filter.\n",
      "Returned list is of length 2000.\n",
      "\n",
      "Found 428437 elements matching the filter.\n",
      "Returned list is of length 2000.\n",
      "\n",
      "Found 569658 elements matching the filter.\n",
      "Returned list is of length 1500.\n",
      "\n",
      "Found 463666 elements matching the filter.\n",
      "Returned list is of length 1500.\n"
     ]
    }
   ],
   "source": [
    "dataset_400_600 = filter_list(data=reformatted_dataset,\n",
    "                              word_count_min=400,\n",
    "                              word_count_max=600,\n",
    "                              quantity=100)\n",
    "dataset_300_399 = filter_list(data=reformatted_dataset,\n",
    "                              word_count_min=300,\n",
    "                              word_count_max=399,\n",
    "                              quantity=1400)\n",
    "dataset_250_299 = filter_list(data=reformatted_dataset,\n",
    "                              word_count_min=250,\n",
    "                              word_count_max=299,\n",
    "                              quantity=1500)\n",
    "dataset_200_249 = filter_list(data=reformatted_dataset,\n",
    "                              word_count_min=200,\n",
    "                              word_count_max=249,\n",
    "                              quantity=2000)\n",
    "dataset_150_199 = filter_list(data=reformatted_dataset,\n",
    "                              word_count_min=150,\n",
    "                              word_count_max=199,\n",
    "                              quantity=2000)\n",
    "dataset_100_149 = filter_list(data=reformatted_dataset,\n",
    "                              word_count_min=100,\n",
    "                              word_count_max=149,\n",
    "                              quantity=1500)\n",
    "dataset_50_99 = filter_list(data=reformatted_dataset,\n",
    "                              word_count_min=50,\n",
    "                              word_count_max=99,\n",
    "                              quantity=1500)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV-file already exists. Will append new rows to existing document. Cancel execution if this is not intended.\n",
      "\n",
      " Generating: 1867/2000\n",
      " API-error. Reattempting API-call\n",
      " Generating: 1904/2000\n",
      " API-error. Reattempting API-call\n",
      " Generating: 2000/2000\n",
      "Abstract generation complete.\n",
      "\n",
      "\n",
      "CSV-file already exists. Will append new rows to existing document. Cancel execution if this is not intended.\n",
      "\n",
      " Generating: 201/2000\n",
      " API-error. Reattempting API-call\n",
      " Generating: 1133/2000\n",
      " API-error. Reattempting API-call\n",
      " Generating: 1250/2000\n",
      " API-error. Reattempting API-call\n",
      " Generating: 1428/2000\n",
      " API-error. Reattempting API-call\n",
      " Generating: 1608/2000\n",
      " API-error. Reattempting API-call\n",
      " Generating: 1657/2000\n",
      " API-error. Reattempting API-call\n",
      " Generating: 1715/2000\n",
      " API-error. Reattempting API-call\n",
      " Generating: 1749/2000\n",
      " API-error. Reattempting API-call\n",
      " Generating: 1938/2000\n",
      " API-error. Reattempting API-call\n",
      " Generating: 2000/2000\n",
      "Abstract generation complete.\n",
      "\n",
      "\n",
      "CSV-file already exists. Will append new rows to existing document. Cancel execution if this is not intended.\n",
      "\n",
      " Generating: 277/1500\n",
      " API-error. Reattempting API-call\n",
      " Generating: 406/1500\n",
      " API-error. Reattempting API-call\n",
      " Generating: 455/1500\n",
      " API-error. Reattempting API-call\n",
      " Generating: 573/1500\n",
      " API-error. Reattempting API-call\n",
      " Generating: 608/1500\n",
      " API-error. Reattempting API-call\n",
      " Generating: 609/1500\n",
      " API-error. Reattempting API-call\n",
      " Generating: 723/1500\n",
      " API-error. Reattempting API-call\n",
      " Generating: 1128/1500\n",
      " API-error. Reattempting API-call\n",
      " Generating: 1198/1500\n",
      " API-error. Reattempting API-call\n",
      " Generating: 1215/1500\n",
      " API-error. Reattempting API-call\n",
      " Generating: 1500/1500\n",
      "Abstract generation complete.\n",
      "\n",
      "\n",
      "CSV-file already exists. Will append new rows to existing document. Cancel execution if this is not intended.\n",
      "\n",
      " Generating: 364/1500\n",
      " API-error. Reattempting API-call\n",
      " Generating: 952/1500\n",
      " API-error. Reattempting API-call\n",
      " Generating: 1003/1500\n",
      " API-error. Reattempting API-call\n",
      " Generating: 1023/1500\n",
      " API-error. Reattempting API-call\n",
      " Generating: 1500/1500\n",
      "Abstract generation complete.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#generate_abstracts(data=dataset_400_600,\n",
    "#                   target_file_name='research_abstracts',\n",
    "#                   target_dir_path='./../../datasets/origins/research-abstracts',\n",
    "#                   start_index=264)\n",
    "#generate_abstracts(data=dataset_300_399,\n",
    "#                   target_file_name='research_abstracts',\n",
    "#                   target_dir_path='./../../datasets/origins/research-abstracts',\n",
    "#                   start_index=851)\n",
    "#generate_abstracts(data=dataset_250_299,\n",
    "#                   target_file_name='research_abstracts',\n",
    "#                   target_dir_path='./../../datasets/origins/research-abstracts')\n",
    "#generate_abstracts(data=dataset_200_249,\n",
    "#                   target_file_name='research_abstracts',\n",
    "#                   target_dir_path='./../../datasets/origins/research-abstracts',\n",
    "#                   start_index=1564)\n",
    "#generate_abstracts(data=dataset_150_199,\n",
    "#                   target_file_name='research_abstracts',\n",
    "#                   target_dir_path='./../../datasets/origins/research-abstracts')\n",
    "generate_abstracts(data=dataset_100_149,\n",
    "                   target_file_name='research_abstracts',\n",
    "                   target_dir_path='./../../datasets/origins/research-abstracts')\n",
    "generate_abstracts(data=dataset_50_99,\n",
    "                   target_file_name='research_abstracts',\n",
    "                   target_dir_path='./../../datasets/origins/research-abstracts')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}