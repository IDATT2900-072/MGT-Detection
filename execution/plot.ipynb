{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting\n",
    "This book is used for producing various plots related to data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from datasets import load_dataset\n",
    "from data_manipulation.data_processing import count_and_reformat\n",
    "from data_manipulation.data_processing import sample_uniform_subset\n",
    "from data_manipulation.data_analysis import plot_distribution, plot_histogram, plot_scatter, plot_loss_curves"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/nicolaisivesind/.cache/huggingface/datasets/gfissore___json/gfissore--arxiv-abstracts-2021-23556c248bdbe0fc/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e01451e2989e493a89d676afd1f9ff30"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Counting words: 100%"
     ]
    }
   ],
   "source": [
    "arxiv = count_and_reformat(dataset=load_dataset(\"gfissore/arxiv-abstracts-2021\")['train'],\n",
    "                           count_column='abstract',\n",
    "                           retain_columns=['title', 'abstract'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plotting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/Users/nicolaisivesind/.cache/huggingface/datasets/csv/default-b7975ec30e73b117/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6c7231361ff4963af9a01fefc2f854c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/Users/nicolaisivesind/.cache/huggingface/datasets/csv/default-6a0f094caf40a32a/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "877b3a8991c14227a2e4bd808dae66c1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chatgpt_abstracts_raw = load_dataset('csv', data_files='../../datasets/origins/research-abstracts/research_abstracts-raw.csv')[\n",
    "    'train']\n",
    "chatgpt_abstracts_clean = load_dataset('csv', data_files='../../datasets/origins/ChatGPT-Research-Abstracts/research_abstracts-final.csv')[\n",
    "    'train']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sorting into lists: 99%\n",
      " Sampling data points: 100%"
     ]
    }
   ],
   "source": [
    "arxiv_10k = random.sample(arxiv, k=10000)\n",
    "uniform = sample_uniform_subset(arxiv, 'word_count', 10000, 50, 600)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_distribution(plots=[{'dataset': arxiv, 'column_name': 'word_count', 'color': 'darkmagenta', 'alpha': 0.6,\n",
    "                          'display': 'arXiv-abstracts-2021 (~2m)', 'mode':False},\n",
    "                         {'dataset': arxiv_10k, 'column_name': 'word_count', 'color': 'red', 'alpha': 0.6,\n",
    "                          'display': 'arXiv-abstracts-2021 random subset (10k)', 'mode':True},\n",
    "                         {'dataset': chatgpt_abstracts_raw, 'column_name': 'real_word_count', 'color': 'blue', 'alpha': 0.6,\n",
    "                          'display': 'ChatGPT-Research-Abstracts, real (10k)', 'mode':False},\n",
    "                         {'dataset': chatgpt_abstracts_raw, 'column_name': 'generated_word_count', 'color': 'limegreen', 'alpha': 0.8,\n",
    "                          'display': 'ChatGPT-Research-Abstracts, generated (10k)', 'mode':True}],\n",
    "                   h_lines=[{'value': 18, 'color': 'grey', 'alpha': 0.8, 'text': 'IASS_10k â‰ˆ 18', 'offset': (400, 1)}],\n",
    "                   v_lines=[{'value': 360, 'color': 'grey', 'alpha': 0.8, 'text': 'WC = 360', 'offset': (5, 50)}],\n",
    "                   start=50,\n",
    "                   end=600,\n",
    "                   x_label='WC (length of data points in words)',\n",
    "                   y_label='n (number of data points)',\n",
    "                   y_lim=(0, 75),\n",
    "                   legend_offset=1.02)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "plot_histogram(plots=[{'dataset': arxiv, 'column_name': 'word_count', 'color': 'red', 'alpha': 0.6,\n",
    "                       'display': 'arXiv-abstracts-2021 (~2m)'},\n",
    "                      {'dataset': chatgpt_abstracts_clean, 'column_name': 'real_word_count', 'color': 'blue', 'alpha': 0.4,\n",
    "                       'display': 'ChatGPT-Research-Abstracts, real (10k)'},\n",
    "                      {'dataset': chatgpt_abstracts_clean, 'column_name': 'generated_word_count', 'color': 'limegreen', 'alpha': 0.8,\n",
    "                       'display': 'ChatGPT-Research-Abstracts, generated (10k)'}],\n",
    "                     start=350,\n",
    "                     end=600,\n",
    "                x_label=\"WC (length of data points in words)\",\n",
    "                y_label=\"n (number of data points)\",\n",
    "                y_lim=(0, 52))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "plot_scatter(plots=[{'dataset': chatgpt_abstracts_raw, 'x': 'real_word_count', 'y': 'generated_word_count', 'color': 'blue', 'alpha': 0.1,\n",
    "                     'display': 'Data point in ChatGPT-Research-Abstracts'}],\n",
    "             correlations=[{'interval': (50, 325), 'spaces': (2, 2, 1), 'positioning':(400, 160), 'color':'magenta', 'alpha':0.8},\n",
    "                           {'interval': (325, 420), 'spaces': (0, 2, 1),'positioning':(400, 120), 'color':'green', 'alpha':0.8},\n",
    "                           {'interval': (420, 600), 'spaces': (0, 4, 1), 'positioning':(400, 80), 'color':'darkblue', 'alpha':0.8},\n",
    "                           {'interval': (50, 600), 'spaces': (2, 0, 1), 'positioning':(400, 40), 'color':'black', 'alpha':0.95}],\n",
    "             d_lines=[{'start': (0, 0), 'increment': (1, 1), 'color': 'orange', 'alpha': 0.8, 'display': 'Perfect correlation', 'offset': (0, 0)}],\n",
    "             v_lines=[{'value': 325, 'color': 'grey', 'alpha': 0.8, 'text': 'x=325', 'offset': (5, 520)},\n",
    "                      {'value': 420, 'color': 'grey', 'alpha': 0.8, 'text': 'x=420', 'offset': (5, 520)}],\n",
    "             x_label='x: Real abstract word count',\n",
    "             y_label='y: Generated abstract word count',\n",
    "             y_lim=(0, 600),\n",
    "             legend_offset=(0.43, 0.95),\n",
    "             average_curve={'color': 'red', 'alpha': 0.8, 'display': 'Average word count correlation', 'offset': (10, 10)},\n",
    "             sigma=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "plot_loss_curves(plots=[{'dataset': chatgpt_abstracts_raw,\n",
    "                         'benchmark': 'real_word_count', 'predicted': 'generated_word_count',\n",
    "                         'positive-color': 'blue','negative-color': 'red', 'alpha': 0.6,\n",
    "                         'positive-display': 'Mean absolute positive deviation (MAPD)',\n",
    "                         'negative-display': 'Mean absolute negative deviation (MAND)',\n",
    "                         'mean-abs-display': 'Mean absolute total deviation (MATD)',\n",
    "                         'mean-abs-color': 'purple'}],\n",
    "                 deviations=[{'zero-text': 'Non-deviates:          ', 'positioning':(465, 30), 'color':'black', 'alpha':0.7},\n",
    "                             {'positive-text': 'Positive deviates:    ', 'positioning':(465, 20), 'color':'blue', 'alpha':0.8},\n",
    "                             {'negative-text': 'Negative deviates:  ', 'positioning':(465, 10), 'color':'red', 'alpha':0.8}],\n",
    "                 v_lines=[{'value': 325, 'color': 'grey', 'alpha': 0.8, 'text': 'x=325', 'offset': (5, 175)},\n",
    "                      {'value': 420, 'color': 'grey', 'alpha': 0.8, 'text': 'x=420', 'offset': (5, 175)}],\n",
    "                 x_label='Target word count',\n",
    "                 y_label='Average absolute deviation',\n",
    "                 legend_offset=(0.43, 0.95),\n",
    "                 sigma=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2543\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage import gaussian_filter1d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_mean_y_per_x(x_values, y_values):\n",
    "    xy_dict = {}\n",
    "    for x, y in zip(x_values, y_values):\n",
    "        if x not in xy_dict:\n",
    "            xy_dict[x] = {'sum': 0, 'count': 0}\n",
    "        xy_dict[x]['sum'] += y\n",
    "        xy_dict[x]['count'] += 1\n",
    "\n",
    "    mean_y_values = {x: y_data['sum'] / y_data['count'] for x, y_data in xy_dict.items()}\n",
    "    return list(mean_y_values.keys()), list(mean_y_values.values())\n",
    "\n",
    "def plot_newline_frequencies(plots: list[dict], x_label=None, y_label=None, title=None,\n",
    "                             legend_coords=(20, 0.05), sigma=2, text_coords=(0.53, 0.7), v_lines=None):\n",
    "\n",
    "    with plt.style.context('ggplot'):\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "        ax.patch.set_facecolor('lightgrey')\n",
    "        ax.patch.set_alpha(0.3)\n",
    "\n",
    "        averages = []\n",
    "        total_paragraph_breaks = []\n",
    "\n",
    "        for plot in plots:\n",
    "            total_w = sum(data_point[plot['word_count']] for data_point in plot['dataset'])\n",
    "            total_p = sum(data_point[plot['column']].count('\\n\\n') + 1 for data_point in plot['dataset'])\n",
    "            total_pb = sum(data_point[plot['column']].count('\\n\\n') for data_point in plot['dataset'])\n",
    "\n",
    "            print(len([data_point for data_point in plot['dataset'] if data_point[plot['word_count']] < 185 and data_point[plot['column']].count('\\n\\n') > 0]))\n",
    "\n",
    "            averages.append((total_w / total_p))\n",
    "            total_paragraph_breaks.append(total_pb)\n",
    "\n",
    "\n",
    "            x_values = [data_point[plot['word_count']] for data_point in plot['dataset']]\n",
    "            y_values = [data_point[plot['word_count']] / (data_point[plot['column']].count('\\n\\n') + 1) for data_point in plot['dataset']]\n",
    "\n",
    "            scatter_plot = ax.scatter(x_values, y_values, alpha=plot['alpha'], color=plot['color'])\n",
    "            scatter_plot.set_label(plot['display'])\n",
    "\n",
    "            x_unique, y_mean = calculate_mean_y_per_x(x_values, y_values)\n",
    "            x_unique, y_mean = zip(*sorted(zip(x_unique, y_mean)))\n",
    "            y_mean_filtered = gaussian_filter1d(y_mean, sigma)\n",
    "\n",
    "            line_plot, = ax.plot(x_unique, y_mean_filtered, color=plot['mean_color'], alpha=0.8)\n",
    "            line_plot.set_label(f\"Mean {plot['display']}\")\n",
    "\n",
    "        ax.text(text_coords[0], text_coords[1], f\"Mean word per pargraph: Real = {averages[0]:.4f}, Generated = {averages[1]:.4f}\\n\"\n",
    "                                                f\"Total paragraph breaks: Real = {total_paragraph_breaks[0]}, Generated = {total_paragraph_breaks[1]}\",\n",
    "                transform=ax.transAxes, color='darkblue')\n",
    "\n",
    "        if x_label:\n",
    "            ax.set_xlabel(x_label)\n",
    "        if y_label:\n",
    "            ax.set_ylabel(y_label)\n",
    "        if title:\n",
    "            ax.set_title(title)\n",
    "\n",
    "        if v_lines:\n",
    "            for v_line in v_lines:\n",
    "                ax.axvline(v_line['value'], color=v_line['color'], linestyle='--', alpha=0.8)\n",
    "                ax.text(v_line['value'] + v_line['offset'][0], v_line['offset'][1], v_line['text'],\n",
    "                        color=v_line['color'])\n",
    "\n",
    "        ax.legend(facecolor='white', loc='upper right', bbox_to_anchor=legend_coords)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plot_newline_frequencies(plots=[{'dataset': chatgpt_abstracts_clean, 'column': 'real_abstract', 'word_count': 'real_word_count', 'color': 'lavender', 'alpha': 0.8, 'display': 'Real abstracts, (CRA-Real)', 'mean_color': 'blue'},\n",
    "                                {'dataset': chatgpt_abstracts_clean, 'column': 'generated_abstract', 'word_count': 'generated_word_count', 'color': 'mistyrose', 'alpha': 0.8, 'display': 'Generated abstracts (CRA-Generated)', 'mean_color': 'red'}],\n",
    "                         x_label='x: Word Count',\n",
    "                         y_label='y: Number of words per paragraph',\n",
    "                         sigma=4,\n",
    "                         legend_coords=(0.45, 0.95),\n",
    "                         text_coords=(0.039, 0.66),\n",
    "                         v_lines=[{'value': 185, 'color': 'lightgrey', 'alpha': 0.8, 'text': 'x=185', 'offset': (5, 280)}])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}