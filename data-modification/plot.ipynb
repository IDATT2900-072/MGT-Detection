{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting\n",
    "This book is used for producing various plots related to data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from datasets import load_dataset\n",
    "from data_processing import count_and_reformat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/nicolaisivesind/.cache/huggingface/datasets/gfissore___json/gfissore--arxiv-abstracts-2021-23556c248bdbe0fc/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a325865b656418ab6a3f7218eb4541a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Counting words: 100%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/Users/nicolaisivesind/.cache/huggingface/datasets/csv/default-73fa189815e75ccc/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "229b2c36077f43a983c09cf0726b9f04"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arxiv = count_and_reformat(dataset=load_dataset(\"gfissore/arxiv-abstracts-2021\")['train'],\n",
    "                           count_column='abstract',\n",
    "                           retain_columns=['title', 'abstract'])\n",
    "\n",
    "chatgpt_abstracts = load_dataset('csv', data_files='../../datasets/origins/research-abstracts/research_abstracts-deduplicated.csv')[\n",
    "    'train']\n",
    "\n",
    "\n",
    "#substitutes = substitute_duplicates_uniform(abstracts, arxiv, 'title', 'word_count', 10000, 50, 600, 42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plotting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/Users/nicolaisivesind/.cache/huggingface/datasets/csv/default-702d18da4aab8662/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f7aa8f696c0040558c075f93902e4d48"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chatgpt_abstracts = load_dataset('csv', data_files='../../datasets/origins/research-abstracts/research_abstracts-uniform.csv')[\n",
    "    'train']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sorting into lists: 99%\n",
      " Sorting into lists: 99%00%\n",
      " Sampling data points: 100%"
     ]
    }
   ],
   "source": [
    "#from data_analysis import plot_distribution, plot_histogram\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from data_processing import sample_uniform_subset\n",
    "\n",
    "def plot_distribution(plots: list[dict], start, end, sigma=2, save_to=None):\n",
    "    # Set the plot style\n",
    "    with plt.style.context('ggplot'):\n",
    "        # Create the figure and axis objects\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "        ax.patch.set_facecolor('lightgrey')\n",
    "        ax.patch.set_alpha(0.3)\n",
    "\n",
    "        for i, plot in enumerate(plots):\n",
    "            counts = np.zeros(end - start + 1)\n",
    "\n",
    "            for data_point in plot['dataset']:\n",
    "                count = data_point[plot['column_name']]\n",
    "\n",
    "                if start <= count <= end:\n",
    "                    index = data_point[plot['column_name']] - start\n",
    "                    counts[index] += 1\n",
    "\n",
    "            # Apply the Gaussian filter\n",
    "            smoothed_counts = gaussian_filter1d(counts, sigma)\n",
    "\n",
    "            # Plot the smoothed data with a label for the legend\n",
    "            x_values = np.arange(start, end + 1)\n",
    "            ax.plot(x_values, smoothed_counts, label=plot['display'], alpha=plot['alpha'], color=plot['color'])\n",
    "\n",
    "        # Set labels and title\n",
    "        ax.set_xlabel('Length of text in words')\n",
    "        ax.set_ylabel('Number of texts')\n",
    "        #ax.set_title('Word count distributions')\n",
    "\n",
    "        # Rotate x-axis labels for better readability\n",
    "        plt.xticks(rotation=90)\n",
    "\n",
    "        # Add a legend\n",
    "        ax.legend(facecolor='white')\n",
    "\n",
    "    # Display the plot\n",
    "    plt.subplots_adjust(left=0.07, bottom=0.143, right=0.93, top=0.943)\n",
    "\n",
    "    if save_to:\n",
    "        plt.savefig(save_to)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_histogram(plots: list[dict], start, end, sigma=2, save_to=None):\n",
    "    bins = end-start+1\n",
    "\n",
    "    # Set the plot style\n",
    "    with plt.style.context('ggplot'):\n",
    "        # Create the figure and axis objects\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "        ax.patch.set_facecolor('lightgrey')\n",
    "        ax.patch.set_alpha(0.3)\n",
    "\n",
    "        for i, plot in enumerate(plots):\n",
    "            counts = []\n",
    "\n",
    "            for data_point in plot['dataset']:\n",
    "                count = data_point[plot['column_name']]\n",
    "\n",
    "                if start <= count <= end:\n",
    "                    counts.append(count)\n",
    "\n",
    "            ax.hist(counts, bins=bins, range=(start, end), alpha=plot['alpha'], label=plot['display'], color=plot['color'])\n",
    "\n",
    "        # Set labels and title\n",
    "        ax.set_xlabel('Length of text in words')\n",
    "        ax.set_ylabel('Number of texts')\n",
    "\n",
    "        # Rotate x-axis labels for better readability\n",
    "        plt.xticks(rotation=90)\n",
    "\n",
    "        # Add a legend\n",
    "        ax.legend(facecolor='white')\n",
    "\n",
    "    # Adjust the plot margins\n",
    "    plt.subplots_adjust(left=0.07, bottom=0.143, right=0.93, top=0.943)\n",
    "\n",
    "    # Save and display the plot\n",
    "    if save_to:\n",
    "        plt.savefig(save_to)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "arxiv_10k = random.sample(arxiv, k=10000)\n",
    "uniform = sample_uniform_subset(arxiv, 'word_count', 10000, 50, 600)\n",
    "\n",
    "plot_distribution(plots=[{'dataset': arxiv, 'column_name': 'word_count', 'color': 'red', 'alpha': 0.6,\n",
    "                       'display': 'Source dataset (2 000 000 data points)'},\n",
    "                         {'dataset': chatgpt_abstracts, 'column_name': 'real_word_count', 'color': 'blue', 'alpha': 0.6,\n",
    "                       'display': 'Selected real abstracts (10 000 data points, uniform word count selection)'},\n",
    "                      {'dataset': chatgpt_abstracts, 'column_name': 'generated_word_count', 'color': 'limegreen', 'alpha': 0.8,\n",
    "                       'display': 'Generated abstracts (10 000 data points\\n'\n",
    "                                  '                                    Instructed to match real abstract word count)'}],\n",
    "                     start=50,\n",
    "                     end=600)\n",
    "\n",
    "plot_distribution(plots=[{'dataset': arxiv_10k, 'column_name': 'word_count', 'color': 'red', 'alpha': 0.6,\n",
    "                       'display': 'Source data subset (10 000 data points, random selection)'},\n",
    "                      {'dataset': chatgpt_abstracts, 'column_name': 'real_word_count', 'color': 'blue', 'alpha': 0.6,\n",
    "                       'display': 'Selected real abstracts (10 000 data points, uniform word count selection)'},\n",
    "                      {'dataset': chatgpt_abstracts, 'column_name': 'generated_word_count', 'color': 'limegreen', 'alpha': 0.8,\n",
    "                       'display': 'Generated abstracts (10 000 data points\\n'\n",
    "                                  '                                    Instructed to match real abstract word count)'}],\n",
    "                     start=50,\n",
    "                     end=600)\n",
    "\n",
    "plot_histogram(plots=[{'dataset': arxiv, 'column_name': 'word_count', 'color': 'red', 'alpha': 0.6,\n",
    "                       'display': 'Source dataset (2 000 000 data points)'},\n",
    "                      {'dataset': chatgpt_abstracts, 'column_name': 'real_word_count', 'color': 'blue', 'alpha': 0.4,\n",
    "                       'display': 'Selected real abstracts (10 000 data points)'},\n",
    "                      {'dataset': chatgpt_abstracts, 'column_name': 'generated_word_count', 'color': 'limegreen', 'alpha': 0.8,\n",
    "                       'display': 'Generated abstracts (10 000 data points\\n'\n",
    "                                  '                                   Instructed to match real abstract word counts)'}],\n",
    "                     start=355,\n",
    "                     end=600)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}